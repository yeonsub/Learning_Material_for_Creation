{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeonsub/models_from_scratch/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_seed(random_seed):\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "\n",
        "set_seed(16)"
      ],
      "metadata": {
        "id": "N9Yzhkxwt9PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN을 이용해서 MNIST 이미지를 학습해 보겠습니다."
      ],
      "metadata": {
        "id": "3IwMtHRlkY3I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K17ypcNXkH1P"
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "mnist_train = datasets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = datasets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         download=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class mnist_dataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        super(mnist_dataset, self).__init__()\n",
        "        self.images = data.data\n",
        "        self.labels = data.targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"images\": self.images[idx].unsqueeze(axis=0)/255,\n",
        "            \"labels\": self.labels[idx]\n",
        "        }\n",
        "\n",
        "train_dataset = mnist_dataset(mnist_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "test_dataset = mnist_dataset(mnist_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "hVLTjAIJkTm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 파라미터를 직접 수정하면서 shape이 어떻게 변화하는지 확인해 보세요!"
      ],
      "metadata": {
        "id": "DdO3oHOWqmD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
        "\n",
        "        '''\n",
        "        convolution layer의 구조를 수정할 경우, 아래 Linear 레이어의 input dimension을 바꿔줘야 합니다.\n",
        "        잘 계산해서 convolution layer의 결과의 차원 수를 모두 곱해서 입력하면 됩니다.\n",
        "        (현재는 self.pool2까지 수행한 결과가 [16, 7, 7] 형태이므로 7*7*16을 넣은 것.)\n",
        "        '''\n",
        "        self.dense = nn.Linear(7*7*16, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size = inputs.shape[0]\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = x.view(batch_size, -1)\n",
        "        outputs = self.dense(x)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def test_shape(self, input_shape=(16, 1, 28, 28)):\n",
        "        dummy_inputs = torch.randn(input_shape)\n",
        "        batch_size = input_shape[0]\n",
        "        print(\"Input shape :\", input_shape, \"\\n\")\n",
        "        with torch.no_grad():\n",
        "            x = self.conv1(dummy_inputs)\n",
        "            print(self.conv1)\n",
        "            print(\"output shape :\", x.shape, \"\\n\")\n",
        "            x = self.conv2(x)\n",
        "            print(self.conv2)\n",
        "            print(\"output shape :\", x.shape, \"\\n\")\n",
        "            x = self.pool1(x)\n",
        "            print(self.pool1)\n",
        "            print(\"output shape :\", x.shape, \"\\n\")\n",
        "            x = self.conv3(x)\n",
        "            print(self.conv3)\n",
        "            print(\"output shape :\", x.shape, \"\\n\")\n",
        "            x = self.conv4(x)\n",
        "            print(self.conv4)\n",
        "            print(\"output shape :\", x.shape, \"\\n\")\n",
        "            x = self.pool2(x)\n",
        "            print(self.pool2)\n",
        "            print(\"output shape :\", x.shape, \"\\n\")\n",
        "            x = x.view(batch_size, -1)\n",
        "            print(\"Reshape Tensor\")\n",
        "            print(\"output shape :\", x.shape, \"\\n\")\n",
        "            outputs = self.dense(x)\n",
        "            print(self.dense)\n",
        "            print(\"output shape :\", outputs.shape)\n",
        "\n",
        "model = CNN()\n",
        "model.test_shape()"
      ],
      "metadata": {
        "id": "0HxamJUnkoje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "cMGetEROrRNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "eA5tcrKjr-cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "loss_track = []\n",
        "epoch_loss = 0\n",
        "\n",
        "for epoch in range(3):\n",
        "    print(\"epoch :\", epoch)\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    for step, data in enumerate(tqdm(train_loader)):\n",
        "        data = {k: v.to(device) for k, v in data.items()}\n",
        "        images = data[\"images\"].float()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, data[\"labels\"])\n",
        "        train_loss.append(loss.detach().cpu().item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = sum(train_loss)/len(train_loss)\n",
        "    loss_track.append(epoch_loss)\n",
        "    print(f\"{epoch} loss :\", epoch_loss)\n"
      ],
      "metadata": {
        "id": "E3QfDxBbsATV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "outputs = []\n",
        "for data in tqdm(test_loader):\n",
        "    data = {k: v.to(device) for k, v in data.items()}\n",
        "    images = data[\"images\"].float()\n",
        "    with torch.no_grad():\n",
        "      output = model(images)\n",
        "    outputs.append(output.cpu())\n",
        "\n",
        "outputs = torch.cat(outputs, dim=0)\n",
        "preds = torch.argmax(outputs, dim=-1)\n",
        "correct = (preds == mnist_test.targets).sum().item()/len(test_dataset)\n",
        "print(f\"model accuracy on test set : {correct*100}\")"
      ],
      "metadata": {
        "id": "65I99RYLYsry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch의 모델 파라미터를 쉽게 확인할 수 있는 방법에 대해 소개드리겠습니다."
      ],
      "metadata": {
        "id": "npr7kKRIufxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "id": "wvrJgiQ9tJSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchsummary\n",
        "\n",
        "torchsummary.summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "id": "8BBM2ZROtR0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_model = nn.Sequential(\n",
        "    nn.Linear(28*28, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)\n",
        "\n",
        "torchsummary.summary(dense_model, (1, 28*28))"
      ],
      "metadata": {
        "id": "OogPleIqtZPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 확인해 보면, 기존의 dense model의 파라미터의 10분의 1만 사용하고도 CNN 모델의 성능이 더 좋은 것을 알 수 있습니다."
      ],
      "metadata": {
        "id": "b0CyTxaMumUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN의 또 다른 장점은, 모델이 이미지를 어떻게 인식하고 있는지를 시각화할 수 있다는 것입니다. 이는 모델의 성능에 대한 분석 수단으로도 활용이 가능합니다."
      ],
      "metadata": {
        "id": "rlc2aa5YyLgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample = train_dataset[0]['images']\n",
        "\n",
        "plt.imshow(sample.squeeze())"
      ],
      "metadata": {
        "id": "qup7DWKZutRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_dataset[0]['images']\n",
        "\n",
        "with torch.no_grad():\n",
        "    x = model.conv1(sample.to(device))\n",
        "    x = model.relu(x)\n",
        "    x = model.conv2(x)\n",
        "    x = model.relu(x)\n",
        "    x = model.pool1(x)\n",
        "    x = model.conv3(x)\n",
        "    x = model.relu(x)\n",
        "    x = model.conv4(x)\n",
        "    x = model.relu(x)\n",
        "    x = model.pool2(x)\n",
        "\n",
        "fig, ax = plt.subplots(4, 4, figsize=(10, 10))\n",
        "for i in range(4*4):\n",
        "    ax[i//4][i%4].imshow(x[i].cpu())"
      ],
      "metadata": {
        "id": "C99hHN0Kw5Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sr6tSRux_8Ib"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}