{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeonsub/Learning_Material_for_Creation/blob/main/neural_odes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDGrAX6_5PQj"
      },
      "source": [
        "## 0. Introduction\n",
        "\n",
        "This is a tutorial on dynamical systems, Ordinary Differential Equations (ODEs)\n",
        "and numerical solvers, and Neural Ordinary Differential Equations (Neural ODEs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjDajbty5kY0"
      },
      "source": [
        "Below, we import our standard libraries. In this tutorial, we will use [PyTorch Lightning](https://www.pytorchlightning.ai/). Additionally, we will use the ODE solvers from [Torchdiffeq](https://github.com/rtqichen/torchdiffeq). You don't need to use GPUs for this tutorial, you can run the entire codebase in a CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3_2l__x1SE6"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import logging\n",
        "import statistics\n",
        "from typing import Optional, List\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "try:\n",
        "    import torchdiffeq\n",
        "except ModuleNotFoundError:\n",
        "    !pip install --quiet torchdiffeq\n",
        "    import torchdiffeq\n",
        "\n",
        "try:\n",
        "    import rich\n",
        "except ModuleNotFoundError:\n",
        "    !pip install --quiet rich\n",
        "    import rich\n",
        "\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError:\n",
        "    !pip install --quiet pytorch-lightning>=1.4\n",
        "    import pytorch_lightning as pl\n",
        "from torchmetrics.classification import Accuracy\n",
        "\n",
        "pl.seed_everything(42)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiR5p0DwnlVF"
      },
      "source": [
        "### Dynamical Systems Primer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8krXfeUfkKr"
      },
      "source": [
        "The most accurate definition of dynamical system is the following:\n",
        "\n",
        "A dynamical system is a triple $$(\\mathcal{S}, \\mathcal{T}, \\Phi)$$ where\n",
        "- $\\mathcal{S}$ is the *state space*\n",
        "- $\\mathcal{T}$ is the *parameter space*, and\n",
        "- $\\Phi: (\\mathcal{T} \\times \\mathcal{S}) \\longrightarrow \\mathcal{S}$ is the evolution.\n",
        "\n",
        "Some notes:\n",
        "- This is a very general definition that includes all sort of dynamical systems that you might encounter.\n",
        "- In this tutorial we deal with ODEs where $\\Phi$ plays the role of the *general solution*: indeed a 1-parameter family of transformations of the state space. $\\mathcal{T}=\\mathbb{R}_{+}$ is the time, and usually, $\\mathcal{S}=\\mathbb{R}^{n}$ is the state space. The evolution takes a point in space (initial value), a point in time, and returns the a point in space. This is the concept of a *flow*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqD1LpT_63VB"
      },
      "source": [
        "## 1. Differential Equations\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1sAPUUxbUws"
      },
      "source": [
        "We will deal with *initial value problems* (IVP) defined by a first-order ODE, and an initial value:\n",
        "\n",
        "$$\\dot{y} = f(y, t), \\quad y(t_{0}) = y_{0},$$\n",
        "\n",
        "where we use the shorthand notation $\\dot{y} := \\frac{\\mathrm{d}y}{\\mathrm{d}t}$ common in physics.\n",
        "\n",
        "A general solution to an ODE is a function $y: I \\times \\mathbb{R}^{n} ⟶ \\mathbb{R}^{n}$: a 1-parameter (usually time is the parameter) family of transformations of the state space. A 1-parameter family of transformations is often called a *flow*. The existence and uniqueness of solutions to an IVP is ensured by the Picard-Lindel&ouml;f theorem, provided the RHS of the ODE is *Lipschitz continuous*. Lipschitz continuity is a property that pops up quite often in ODE-related results in ML so we provide a definition here:\n",
        "\n",
        "A function $f: X \\subset \\mathbb{R}^{n} ⟶ \\mathbb{R}^{n}$ is called *Lipschitz continuous* (with constant $\\lambda$) if\n",
        "\n",
        "$$|| f(x_{1}) - f(x_{2}) || \\leq \\lambda ||x_{1} - x_{2}|| \\quad \\forall x_{1},x_{2} \\in X.$$\n",
        "\n",
        "Note that this is a stronger condition than just continuity.\n",
        "\n",
        "The rest of the tutorial is dedicated to numerical integration methods for finding solutions to IVPs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsNijO_-rK2Y"
      },
      "source": [
        "### Euler method\n",
        "\n",
        "Solving differential equations analytically is not an option for complicated $f$s, given, for example, by neural networks. We need numerical solvers.\n",
        "Runge-Kutta methods are a family of iterative methods that find approximate solutions to IVPs. We will start with the simplest and most intuitive Runge-Kutta method, the **Euler** method.\n",
        "\n",
        "Consider the IVP\n",
        "\n",
        "$$\\dot{y} = f(y, t), \\quad y(t_{0}) = y_{0}.$$\n",
        "\n",
        "where $y(t_0)$, and $f$ are given.\n",
        "\n",
        "Pick a step-size $h>0$, a number of steps $N$, and define\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "&y_{n+1} = y_{n} + hf(y_{n}, t_{n}) \\\\\n",
        "&t_{n+1} = t_{n} + h.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This is the most basic numerical integrator. One intuition behind the Euler method is that we are evolving the trajectories by iteratively taking small steps in the direction of the slope.\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/DL2/Dynamical_systems/Euler_method.svg.png?raw=1\" width=\"200px\"></center>\n",
        "\n",
        "(Figure credit: [Wikipedia](https://upload.wikimedia.org/wikipedia/commons/1/10/Euler_method.svg))\n",
        "\n",
        "### Derivation\n",
        "\n",
        "The mathematical explanation behind that intuition can be derived by taking  the forward finite difference formula for the derivative:\n",
        "\n",
        "$$\n",
        "\\dot{y}(t_0) = \\lim_{h\\to 0} \\frac{y(t_0+h)-y(t_0)}{h} \\approx \\frac{y(t_0+h)-y(t_0)}{h}.\n",
        "$$\n",
        "\n",
        "By rearranging the terms, we can derive the forward Euler method.\n",
        "\n",
        "We can also explain how this method works by considering the Taylor expansion of the solution $y(t)$ around $t_{n+1}$\n",
        "\n",
        "$$\n",
        "y(t_{n+1}) = y(t_n) + h \\frac{\\mathrm{d}y}{\\mathrm{d}t}\\Big\\vert_{t_n} + O\\big(h^2\\big),\n",
        "$$\n",
        "\n",
        "and using the fact that $\\frac{\\mathrm{d}y}{\\mathrm{d}t}\\big\\vert_{t_n} = \\dot{y}_{t_n} = f(y_n, t_n)$. We are left with\n",
        "\n",
        "$$\n",
        "y(t_{n+1}) = y(t_n) + h f(y_n, t_n)  + O\\big(h^2\\big),\n",
        "$$\n",
        "\n",
        "which is precisely the Euler method step above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1T1HX7wOkDs"
      },
      "source": [
        "### Runge-Kutta Methods\n",
        "\n",
        "Euler method is the simplest numerical integrator in a family of methods known as Runge-Kutta methods. Here we describe the RK4 method.\n",
        "\n",
        "Consider the same IVP as above. Again, pick a step-size $h>0$, a number of steps $N$, and define\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "&y_{n+1} = y_{n} + \\frac{1}{6}h(k_{1} + 2k_{2} + 2k_{3} + k_{4}) \\\\\n",
        "&t_{n+1} = t_{n} + h\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "for $n=0, 1, 2, 3, \\dots, N$ with\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "&k_{1} = f\\left(y_{n}, t_{n}\\right) \\\\\n",
        "&k_{2} = f\\left(y_{n} + h\\frac{k_{1}}{2}, t_{n} + \\frac{h}{2}\\right) \\\\\n",
        "&k_{3} = f\\left(y_{n} + h\\frac{k_{2}}{2}, t_{n} + \\frac{h}{2}\\right) \\\\\n",
        "&k_{4} = f\\left(y_{n} + hk_{3}, t_{n} + h\\right).\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "NB: As you probably noticed, Euler method is just RK4 but considering only $k_1$.\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/DL2/Dynamical_systems/RK4.png?raw=1\" width=\"800px\"></center>\n",
        "\n",
        "(Figure credit: [Wikipedia](https://upload.wikimedia.org/wikipedia/commons/7/7e/Runge-Kutta_slopes.svg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCHKgKH3yE9Q"
      },
      "source": [
        "#### Intuition\n",
        "\n",
        "Here we give an intuitive explanation of why this method approximates solutions to IVPs. As with the Euler method, we will use the Taylor expansion of the solution.\n",
        "\n",
        "Let $y(t)$ be the solution. Let us wite the Taylor expansion of $y(t)$ in the neighborhood of $t_n$ to the $h^{2}$ term:\n",
        "\n",
        "$$\n",
        "y(t_{n+1}) = y(t_n) + h \\frac{dy}{dt}\\Big|_{t_n} + \\frac{h^2}{2} \\frac{d^{2}y}{dt^{2}}\\Big|_{t_n} + O\\big(h^3\\big).\n",
        "$$\n",
        "\n",
        "we know that $\\frac{dy}{dt}\\big|_{t_n} = f(y_n, t_n)$ and therefore\n",
        "\n",
        "$$\n",
        "\\frac{d^{2}y}{dt^{2}}\\Big|_{t_n} = \\frac{df(y, t)}{dt}\\Big|_{t_n} = \\frac{\\partial f}{\\partial t}\\Big|_{t_n} + f \\frac{\\partial f}{\\partial y}\\Big|_{t_n},\n",
        "$$\n",
        "\n",
        "where we used the chain rule. The Taylor expansion becomes\n",
        "\n",
        "$$\n",
        "y(t_{n+1}) = y(t_n) + h f(y_n, t_n) + \\frac{h^2}{2} \\left[\\frac{\\partial f}{\\partial t}\\Big|_{t_n} + f \\frac{\\partial f}{\\partial y}\\Big|_{t_n}\\right] + O\\big(h^3\\big).\n",
        "$$\n",
        "\n",
        "If we look at $k_2$ we can Taylor expand it correctly to $O\\big(h^{3}\\big)$ as\n",
        "\n",
        "$$\n",
        "k_2 = f(y_{n} + \\beta k_{1}, t_{n} + \\alpha h) = h \\left( f(y_n, t_n) + \\alpha h \\frac{\\partial f}{\\partial t}\\Big|_{t_n} + \\beta f \\frac{\\partial f}{\\partial y}\\Big|_{t_n} \\right) + O\\big(h^3\\big),\n",
        "$$\n",
        "\n",
        "which is precisely the third term in the Taylor expansion of $y(t_n)$. Comparing with the previous equation we find conditions on $\\alpha$ and $\\beta$. Note that the value of these coefficients depends on the order to which we decide to stop.\n",
        "Higher order coefficients can be computed in the same way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkDqGMDWGIPu"
      },
      "source": [
        "#### Approximation errors\n",
        "\n",
        "This method is called *classic Runge-Kutta* or *RK4*. This is a fourth-order method meaning that the *local truncation error* is of order $O\\big(h^{5}\\big)$, and the *total truncation error* is of order $O\\big(h^{4}\\big)$. Local truncation and total accumulation errors are defined as follows:\n",
        "\n",
        "For a one-step integration method, such as RK4, of form\n",
        "\n",
        "$$\n",
        "y_{n+1} = y_{n} + hA(y_{n}, t_{n}, h, f),\n",
        "$$\n",
        "\n",
        "the *local truncation error* at time $t_{n+1}$, $\\tau_{n+1}$ is\n",
        "\n",
        "$$\n",
        "\\tau_{n+1} = y(t_{n+1}) - y(t_{n}) - hA(y_{n}, t_{n}, h, f).\n",
        "$$\n",
        "\n",
        "The *total truncation error* at time $t_{n+1}$, $e_{n+1}$ is\n",
        "\n",
        "$$\n",
        "e_{n+1} = y(t_{n+1}) - ( y_{0} + hA(y_{0}, t_{0}, h, f) + \\dots + hA(y_{n}, t_{n}, h, f)).\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABRkVIPf0bJa"
      },
      "source": [
        "#### Example: Lotka-Volterra equations\n",
        "Consider the IVP\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\dot{x} = x - xy \\\\\n",
        "\\dot{y} = xy - y,\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "with initial value $(x_{0}, y_{0}) = (1, 2)$. There is no closed form solution to this system of ODEs. We compare performances of RK4 and simple Euler for different values of step-size $h$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipQ-fdFkrJMB"
      },
      "outputs": [],
      "source": [
        "def LV(x, y):\n",
        "  return np.array([x - x*y, x*y - y])\n",
        "\n",
        "def rk4(f, x0, y0, h, n):\n",
        "\n",
        "    v = np.zeros((n + 1, 2))\n",
        "    v[0] = np.array([x0, y0])\n",
        "    x = x0\n",
        "    y = y0\n",
        "    for i in range(1, n + 1):\n",
        "        k1 = h*f(x, y)\n",
        "        k2 = h*f(x + 0.5*k1[0], y + 0.5*k1[1])\n",
        "        k3 = h*f(x + 0.5*k2[0], y + 0.5*k2[1])\n",
        "        k4 = h*f(x + k3[0], y + k3[1])\n",
        "        v[i] =  v[i-1] + (k1 + k2 + k2 + k3 + k3 + k4)/6\n",
        "        x = v[i,0]\n",
        "        y = v[i,1]\n",
        "\n",
        "    t = np.array([i*h for i in range(0, n+1)])\n",
        "    return t, v\n",
        "\n",
        "def euler(f, x0, y0, h, n):\n",
        "\n",
        "    v = np.zeros((n + 1, 2))\n",
        "    v[0] = np.array([x0, y0])\n",
        "    x = x0\n",
        "    y = y0\n",
        "\n",
        "    for i in range(1, n + 1):\n",
        "        v[i] =  v[i-1] + h*f(x, y)\n",
        "        x = v[i,0]\n",
        "        y = v[i,1]\n",
        "\n",
        "    t = np.array([i*h for i in range(0, n+1)])\n",
        "    return t, v\n",
        "\n",
        "def plot_integrator(v_euler, v_rk4, t_euler, t_rk4, v_true, t_true, h):\n",
        "\n",
        "    fig = plt.figure(figsize=(18,8))\n",
        "    ax0 = fig.add_subplot(121)\n",
        "    ax1 = fig.add_subplot(122)\n",
        "\n",
        "    ax0.plot(t_euler, v_euler, marker = 'x')\n",
        "    ax1.plot(t_rk4, v_rk4, marker = 'x')\n",
        "\n",
        "    ax0.plot(t_true, v_true)\n",
        "    ax1.plot(t_true, v_true)\n",
        "\n",
        "    ax0.set_ylim(0, 3.5)\n",
        "    ax1.set_ylim(0, 3.5)\n",
        "\n",
        "    ax0.set_xlabel(r\"t\", fontsize=25)\n",
        "    ax0.set_title(\"Euler, $h=$\"+h, fontsize=25)\n",
        "    ax0.legend([\"x Euler\", \"y Euler\", \"x True\", \"y True\"])\n",
        "    ax1.set_xlabel(r\"$t$\", fontsize=25)\n",
        "    ax1.set_title(\"RK4, $h=$\"+h, fontsize=25)\n",
        "    ax1.legend([\"x RK4\", \"y RK4\", \"x True\", \"y True\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMCovDLPb4TS"
      },
      "outputs": [],
      "source": [
        "h = 0.2\n",
        "\n",
        "t_euler, v_euler = euler(LV, 1., 2., h, 60)\n",
        "t_rk4, v_rk4 = rk4(LV, 1., 2., h, 60)\n",
        "t_true, v_true = rk4(LV, 1., 2., 0.003, 4000)\n",
        "\n",
        "plot_integrator(v_euler, v_rk4, t_euler, t_rk4, v_true, t_true, str(h))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YkNZ8UognaW"
      },
      "source": [
        "### Phase space and phase portrait\n",
        "\n",
        "It is useful to introduce the concept of phase space and phase portrait. Let us consider the differential equation of the simple pendulum of mass 1, length 1, and $g$ set to 1 for convenience:\n",
        "\n",
        "$$\n",
        "\\ddot{\\theta} + \\sin{\\theta} = 0.\n",
        "$$\n",
        "\n",
        "This is a second-order ODE, but it can be transformed in the following equivalent system of first-order ODEs by introducing the auxiliary variable $p_{\\theta} = \\dot{\\theta}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "&\\dot{\\theta} = p_{\\theta} \\\\\n",
        "&\\dot{p_{\\theta}} = \\sin(\\theta).\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "$S^{1}\\times\\mathbb{R}$ is called the *phase space*, and $(\\theta, p_{\\theta}) \\in S^{1}\\times\\mathbb{R}$ are called *phase space variables* ($\\theta$ is periodic and therefore lives in $S^{1} = \\{x \\mod 2\\pi | x \\in \\mathbb{R}\\}$).\n",
        "\n",
        "Given a solution $(\\theta(t), p_{\\theta}(t))$ we can represent it as a path in the phase space $S^{1}\\times\\mathbb{R}$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xj2XynU6oPYD"
      },
      "outputs": [],
      "source": [
        "def pendulum(x, y):\n",
        "  return np.array([y, -np.sin(x)])\n",
        "\n",
        "def plot_phase_space(v):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,6))\n",
        "    ax0 = fig.add_subplot(111)\n",
        "\n",
        "    ax0.plot([p[0] for p in v], [p[1] for p in v])\n",
        "\n",
        "    ax0.set_xlabel(r\"$\\theta$\", fontsize=25)\n",
        "    ax0.set_ylabel(r\"$p_{\\theta}$\", fontsize=25)\n",
        "    ax0.set_title(\"Phase space\", fontsize=25)\n",
        "    ax0.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwdW-bJ2opz_"
      },
      "outputs": [],
      "source": [
        "t_pendulum, v_pendulum = rk4(pendulum, 1., 1., 0.1, 100)\n",
        "plot_phase_space(v_pendulum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM7cpqWDqRCs"
      },
      "source": [
        "A collection of paths in the phase space is called *phase space portrait* (or phase space diagram, or sometimes state space diagram), which can be thought as a geometric representation of the trajectories (here solutions of a system of ODEs) of a dynamical system in the phase plane. In a phase space portrait each initial conditions is represented by a different curve, or in the case of trivial solution (such as $(0, 0)$ in our example)  a point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHGZX7KkqQmr"
      },
      "outputs": [],
      "source": [
        "def plot_phase_space_pendulum(V):\n",
        "\n",
        "    fig = plt.figure(figsize=(18,8))\n",
        "    ax0 = fig.add_subplot(121)\n",
        "    for v in V:\n",
        "      ax0.plot([p[0] for p in v], [p[1] for p in v], color='b')\n",
        "\n",
        "    ax0.set_xlabel(r\"$\\theta$\", fontsize=25)\n",
        "    ax0.set_ylabel(r\"$p_{\\theta}$\", fontsize=25)\n",
        "    ax0.set_title(\"Phase space portrait\", fontsize=25)\n",
        "    ax0.set_aspect('equal')\n",
        "\n",
        "def plot_phase_space_LV(V):\n",
        "\n",
        "    fig = plt.figure(figsize=(18,8))\n",
        "    ax0 = fig.add_subplot(121)\n",
        "    for v in V:\n",
        "      ax0.plot([p[0] for p in v], [p[1] for p in v], color='b')\n",
        "\n",
        "    ax0.set_xlabel(r\"$x$\", fontsize=25)\n",
        "    ax0.set_ylabel(r\"$y$\", fontsize=25)\n",
        "    ax0.set_title(\"Phase space portrait\", fontsize=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbXzqnVZqpy_"
      },
      "outputs": [],
      "source": [
        "IV = [[5*i, -i] for i in np.linspace(-2, 2, 99)] # initial values\n",
        "paths = []\n",
        "for iv in IV:\n",
        "  t, v = rk4(pendulum, iv[0], iv[1], 0.1, 70)\n",
        "  paths.append(v)\n",
        "\n",
        "plot_phase_space_pendulum(paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHfMxDWxwu5F"
      },
      "source": [
        "We can plot the phase space of the Lotka-Volterra system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHaL4-WDwQ0N"
      },
      "outputs": [],
      "source": [
        "IV = [[i, i] for i in np.linspace(0, 1, 20)] # initial values\n",
        "paths = []\n",
        "for iv in IV:\n",
        "  t, v = rk4(LV, iv[0], iv[1], 0.01, 1000)\n",
        "  paths.append(v)\n",
        "\n",
        "plot_phase_space_LV(paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcVgfEnz6sH9"
      },
      "source": [
        "## 2. Neural ODEs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoog8q-S6sIB"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "Given the intriguing properties of ODEs/solvers and the centuries-long\n",
        "literature on the topic, it seems intriguing to combine them\n",
        "with neural networks, i.e. try to model the transition function with a neural network. This combination could yield a powerful modelling tool, since neural networks are universal function approximators &mdash;they can in theory approximate any differentiable function to an arbitrary precision.\n",
        "\n",
        "Remembering our earlier definitions, we have a first-order ODE:\n",
        "$$\\mathbf{\\dot{y}}(t) = f(t, \\mathbf{y}(t), \\theta),\\quad \\mathbf{y}(t_0) = y_0,\\quad f: \\mathbb{R} \\times \\mathbb{R}^n \\to \\mathbb{R}^n $$\n",
        "\n",
        "Our goal is to solve initial value problems (IVP), i.e. predict $\\mathbf{y}(t_1)$ given $\\mathbf{y}(t_0)$.\n",
        "\n",
        "$$\n",
        "\\mathbf{y}(t_1) = \\mathbf{y}(t_0) + \\int_{t_0}^{t_1} f(\\mathbf{y}(t), t, \\theta)\n",
        "\\mathrm{d}t = \\textrm{ODESolve}(\\mathbf{y}(t_0), f, t_0, t_1, \\theta)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8rSrn8l6sIE"
      },
      "source": [
        "We can use a numerical solver to perform the forward pass and solve the IVP. If we use, for example, Euler's method, we have the following update rule:\n",
        "\n",
        "$$\n",
        "\\mathbf{y}(t+h) = \\mathbf{y}(t) + hf(\\mathbf{y}(t), t)\n",
        "$$\n",
        "\n",
        "This formula looks almost identical to a ResNet block, and this was one of the main motivations for Neural ODEs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PybotKR6TkhM"
      },
      "source": [
        "### Comparison to Resnets\n",
        "\n",
        "Many popular deep learning architectures like ResNets$^2$ update hidden\n",
        "states by employing residual connections:\n",
        "\n",
        "$$\n",
        "  \\mathbf{y}_{l+1} = \\mathbf{y}_l + f(\\mathbf{y}_l, \\theta_l)\n",
        "$$\n",
        "\n",
        "where $f$ is a neural network with parameters $\\theta_l$, and $\\mathbf{y}_l$ and\n",
        "$\\mathbf{y}_{l+1}$ are the hidden states at subsequent layers, $l \\in \\{0,\n",
        "\\ldots, L\\}$.\n",
        "\n",
        "These updates can be seen as Euler discretizations of continuous transformations.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathbf{\\dot{y}} &= f(\\mathbf{y}, t, \\theta)\n",
        "\\\\\n",
        "&\\Bigg\\downarrow \\ \\textrm{Euler Discretization}\n",
        "\\\\\n",
        "\\mathbf{y}_{n+1} &= \\mathbf{y}_n + h f(\\mathbf{y}_n, t_n, \\theta)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Circling back to the continuous realm again, what happens in a residual network (with step sizes $h$) if we consider the continuous limit of each discrete layer in the network? In other words, what happens as we add more layers and take smaller\n",
        "steps? The answer seems rather astounding: instead of having a discrete number of layers between the input and output domains, we allow the evolution of the hidden states to become continuous!\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/DL2/Dynamical_systems/resnet_vs_odenet.png?raw=1\" width=\"600px\"></center>\n",
        "\n",
        "(Figure credit: https://arxiv.org/abs/1806.07366)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80AJI8K4f9lv"
      },
      "source": [
        "$^2$ He, Kaiming, et al. \"**Deep residual learning for image recognition**\". CVPR 2016. https://arxiv.org/abs/1512.03385"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AABvOFup6sIG"
      },
      "source": [
        "### Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEVBkgyj6sIH"
      },
      "source": [
        "We now have a way to perform the forward pass for our model. How do we\n",
        "backpropagate and train the network, though?\n",
        "\n",
        "One very straightforward way to perform backprop is to to back-propagate through\n",
        "the solver. This would work since the forward pass operations are continuous and\n",
        "differentiable. The problem, however, is that this incurs a\n",
        "high-memory cost and we would need to save all intermediate activations of the\n",
        "solver.\n",
        "\n",
        "More importantly, though, our goal should be to try to approximate the exact derivative, rather than differentiating the approximation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkR84DMD0rYi"
      },
      "source": [
        "We want to optimize our scalar-valued loss function $L$ with respect to the model parameters $\\theta$.\n",
        "\n",
        "$$\n",
        "L(\\mathbf{x}(t_1)) = L\\left(\\mathbf{x}(t_0) + \\int_{t_0}^{t_1} f(\\mathbf{x}(t), t,\n",
        "\\theta)\n",
        "\\mathrm{d}t\\right) = L\\left(\\textrm{ODESolve}(\\mathbf{x}(t_0), f, t_0, t_1, \\theta)\\right)\n",
        "$$\n",
        "\n",
        "To optimize $L$ we require gradients with respect to $\\theta$.\n",
        "The problem is to efficiently calculate $\\frac{\\mathrm{d}L(\\mathbf{x}(t_1))}{\\mathrm{d}\\theta}$ without storing all the function activations from the forward pass.\n",
        "**Adjoint method to the rescue**! The adjoint sensitivity method was developed in 1962 by Pontryagin et al.$^1$\n",
        "It leverages the fact that the forward pass is the solution to an ODE, and computes gradients by solving a second, augmented ODE backwards in time.\n",
        "\n",
        "Similar to standard neural networks, we start with determining how the gradient of the loss depends on the hidden state. This quantity is called the *adjoint* $\\mathbf{a}(t) = \\frac{\\partial L}{\\partial \\mathbf{x}(t)}$.\n",
        "It satisfies the following IVP:\n",
        "\n",
        "$$\n",
        " \\dot{\\mathbf{a}}(t) = -\\mathbf{a}(t)^{\\top} \\frac{\\partial f(\\mathbf{x}(t), t,\n",
        "\\theta)}{\\partial \\mathbf{x}}, \\quad \\mathbf{a}(t_1) = \\frac{\\partial L}{\\partial \\mathbf{x}(t_1)}.\n",
        "$$\n",
        "\n",
        "Thus, starting from the initial (remember we are running backwards) value $\\mathbf{a}(t_1) = \\frac{\\partial L}{\\partial \\mathbf{x}(t_1)}$, we can compute $\\mathbf{a}(t_0) = \\frac{\\partial L}{\\partial \\mathbf{x}(t_0)}$ by another call to an ODE solver.\n",
        "\n",
        "Finally, computing the gradients with respect to the parameters $\\theta$ requires evaluating a third integral,\n",
        "which depends on both $\\mathbf{x}(t)$ and $\\mathbf{a}(t)$:\n",
        "\n",
        "$$ \\frac{\\mathrm{d}L}{\\mathrm{d}\\theta} = -\\int_{t_1}^{t_0} \\mathbf{a}(t)^{\\top}\\frac{\\partial f}{\\partial \\theta} \\mathrm{d}t,\n",
        "$$\n",
        "\n",
        "So this method trades off computation for memory – in fact the memory requirement for this gradient calculation is $\\mathcal{O}(1)$ with respect to the number of layers!\n",
        "\n",
        "[Here](https://vaipatel.com/deriving-the-adjoint-equation-for-neural-odes-using-lagrange-multipliers/#:~:text=Luckily%2C%20a%20very%20well%2Dknown,to%20store%20intermediate%20function%20evaluations.) you can find a very good explanation of the following result based on Lagrange multipliers:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk9aW7-KYs7a"
      },
      "source": [
        "$^1$ Pontryagin, L.S. et al. \"**The mathematical theory of optimal processes**\". 1962"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W57p8-RxA_68"
      },
      "source": [
        "The full algorithm for *reverse mode auto-differentiation* is as follows:\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/DL2/Dynamical_systems/neural_ode_algorithm.png?raw=1\" width=\"800px\"></center>\n",
        "\n",
        "(Figure credit: https://arxiv.org/abs/1806.07366)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljMAcoGo2Sa6"
      },
      "source": [
        "### Time to program some Neural ODEs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhROS4pC1VJN"
      },
      "source": [
        "In this tutorial we will be working will Half Moons Dataset, a non-linearly separable, binary classification dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEzi1Zm5oznf"
      },
      "source": [
        "This tutorial has been based on the excellent TorchDyn tutorials (https://github.com/DiffEqML/torchdyn), as well as the original TorchDiffEq examples (https://github.com/rtqichen/torchdiffeq)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U-TcvDQjUNW"
      },
      "outputs": [],
      "source": [
        "class MoonsDataset(Dataset):\n",
        "    \"\"\"Half Moons Classification Dataset\n",
        "\n",
        "    Adapted from https://github.com/DiffEqML/torchdyn\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples=100, noise_std=1e-4):\n",
        "        self.num_samples = num_samples\n",
        "        self.noise_std = noise_std\n",
        "        self.X, self.y = self.generate_moons(num_samples, noise_std)\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_moons(num_samples=100, noise_std=1e-4):\n",
        "        \"\"\"Creates a *moons* dataset of `num_samples` data points.\n",
        "        :param num_samples: number of data points in the generated dataset\n",
        "        :type num_samples: int\n",
        "        :param noise_std: standard deviation of noise magnitude added to each data point\n",
        "        :type noise_std: float\n",
        "        \"\"\"\n",
        "        num_samples_out = num_samples // 2\n",
        "        num_samples_in = num_samples - num_samples_out\n",
        "        theta_out = np.linspace(0, np.pi, num_samples_out)\n",
        "        theta_in = np.linspace(0, np.pi, num_samples_in)\n",
        "        outer_circ_x = np.cos(theta_out)\n",
        "        outer_circ_y = np.sin(theta_out)\n",
        "        inner_circ_x = 1 - np.cos(theta_in)\n",
        "        inner_circ_y = 1 - np.sin(theta_in) - 0.5\n",
        "\n",
        "        X = np.vstack([np.append(outer_circ_x, inner_circ_x),\n",
        "                       np.append(outer_circ_y, inner_circ_y)]).T\n",
        "        y = np.hstack([np.zeros(num_samples_out), np.ones(num_samples_in)])\n",
        "\n",
        "        if noise_std is not None:\n",
        "            X += noise_std * np.random.rand(num_samples, 2)\n",
        "\n",
        "        X = torch.Tensor(X)\n",
        "        y = torch.LongTensor(y)\n",
        "        return X, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp3oUp6R5xy5"
      },
      "outputs": [],
      "source": [
        "def plot_binary_classification_dataset(X, y, title=None):\n",
        "    CLASS_COLORS = ['coral', 'darkviolet']\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.scatter(X[:, 0], X[:, 1], color=[CLASS_COLORS[yi.int()] for yi in y], alpha=0.6)\n",
        "    ax.set_aspect('equal')\n",
        "    if title is not None:\n",
        "        ax.set_title(title)\n",
        "\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJvnWXtRjah7"
      },
      "source": [
        "Let's create a sample dataset and visualize it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeRhrhyakAxQ"
      },
      "outputs": [],
      "source": [
        "sample_dataset = MoonsDataset(num_samples=400, noise_std=1e-1)\n",
        "fig, ax = plot_binary_classification_dataset(sample_dataset.X, sample_dataset.y, title='Half Moons Dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKVotJSPAEVu"
      },
      "source": [
        "Let's now create the train, validation, and test sets, with their corresponding data loaders. We will create a single big dataset and randomly split it in train, val, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Unu7kGuvDJ0w"
      },
      "outputs": [],
      "source": [
        "def split_dataset(dataset_size:int, split_percentages:List[float]) -> List[int]:\n",
        "    split_sizes = [int(p * dataset_size) for p in split_percentages]\n",
        "    split_sizes[0] += dataset_size - sum(split_sizes)\n",
        "    return split_sizes\n",
        "\n",
        "\n",
        "class ToyDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, dataset_size:int, split_percentages:Optional[float]=None):\n",
        "        super().__init__()\n",
        "        self.dataset_size = dataset_size\n",
        "        if split_percentages is None:\n",
        "            split_percentages = [0.8, 0.1, 0.1]\n",
        "        self.split_sizes = split_dataset(self.dataset_size, split_percentages)\n",
        "\n",
        "    def prepare_data(self):\n",
        "        pass\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None):\n",
        "        pass\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_loader = torch.utils.data.DataLoader(self.train_set, batch_size=len(self.train_set), shuffle=True)\n",
        "        return train_loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        val_loader = torch.utils.data.DataLoader(self.val_set, batch_size=len(self.val_set), shuffle=False)\n",
        "        return val_loader\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        test_loader = torch.utils.data.DataLoader(self.test_set, batch_size=len(self.test_set), shuffle=False)\n",
        "        return test_loader\n",
        "\n",
        "\n",
        "class HalfMoonsDataModule(ToyDataModule):\n",
        "    def __init__(self, dataset_size:int, split_percentages:Optional[float]=None):\n",
        "        super().__init__(dataset_size, split_percentages=split_percentages)\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None):\n",
        "        dataset = MoonsDataset(num_samples=self.dataset_size, noise_std=1e-1)\n",
        "        self.train_set, self.val_set, self.test_set = torch.utils.data.random_split(dataset, self.split_sizes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN1fT8nQfVHJ"
      },
      "source": [
        "Now we define the core of our Neural ODE model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtc_wgmJ0FIv"
      },
      "outputs": [],
      "source": [
        "class _ODEFunc(nn.Module):\n",
        "    def __init__(self, module, autonomous=True):\n",
        "        super().__init__()\n",
        "        self.module = module\n",
        "        self.autonomous = autonomous\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        if not self.autonomous:\n",
        "            x = torch.cat([torch.ones_like(x[:, [0]]) * t, x], 1)\n",
        "        return self.module(x)\n",
        "\n",
        "\n",
        "class ODEBlock(nn.Module):\n",
        "    def __init__(self, odefunc: nn.Module, solver: str = 'dopri5',\n",
        "                 rtol: float = 1e-4, atol: float = 1e-4, adjoint: bool = True,\n",
        "                 autonomous: bool = True):\n",
        "        super().__init__()\n",
        "        self.odefunc = _ODEFunc(odefunc, autonomous=autonomous)\n",
        "        self.rtol = rtol\n",
        "        self.atol = atol\n",
        "        self.solver = solver\n",
        "        self.use_adjoint = adjoint\n",
        "        self.integration_time = torch.tensor([0, 1], dtype=torch.float32)\n",
        "\n",
        "    @property\n",
        "    def ode_method(self):\n",
        "        return torchdiffeq.odeint_adjoint if self.use_adjoint else torchdiffeq.odeint\n",
        "\n",
        "    def forward(self, x: torch.Tensor, adjoint: bool = True, integration_time=None):\n",
        "        integration_time = self.integration_time if integration_time is None else integration_time\n",
        "        integration_time = integration_time.to(x.device)\n",
        "        ode_method =  torchdiffeq.odeint_adjoint if adjoint else torchdiffeq.odeint\n",
        "        out = ode_method(\n",
        "            self.odefunc, x, integration_time, rtol=self.rtol,\n",
        "            atol=self.atol, method=self.solver)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85qy0gcEfcsc"
      },
      "source": [
        "We will wrap everything together in a **LightningModule**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf0DOjRPks9v"
      },
      "outputs": [],
      "source": [
        "class Learner(pl.LightningModule):\n",
        "    def __init__(self, model:nn.Module, t_span:torch.Tensor, learning_rate:float=5e-3):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.t_span = t_span\n",
        "        self.learning_rate = learning_rate\n",
        "        self.accuracy = Accuracy(task='binary', num_classes=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def inference(self, x, time_span):\n",
        "        return self.model(x, adjoint=False, integration_time=time_span)\n",
        "\n",
        "    def inference_no_projection(self, x, time_span):\n",
        "        return self.model.forward_no_projection(x, adjoint=False, integration_time=time_span)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self(x)\n",
        "        y_pred = y_pred[-1]  # select last point of solution trajectory\n",
        "        loss = nn.CrossEntropyLoss()(y_pred, y)\n",
        "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self(x)\n",
        "        y_pred = y_pred[-1]  # select last point of solution trajectory\n",
        "        loss = nn.CrossEntropyLoss()(y_pred, y)\n",
        "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
        "        acc = self.accuracy(y_pred.argmax(dim=-1), y) # Changed: Use argmax to get predicted class labels\n",
        "        self.log('val_accuracy', acc, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self(x)\n",
        "        y_pred = y_pred[-1]  # select last point of solution trajectory\n",
        "        loss = nn.CrossEntropyLoss()(y_pred, y)\n",
        "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
        "        acc = self.accuracy(y_pred.argmax(dim=-1), y) # Changed: Use argmax to get predicted class labels\n",
        "        self.log('test_accuracy', acc, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V_GV2G0fudi"
      },
      "source": [
        "Finally, it is time to actually define a Neural ODE and train it.\n",
        "We will use a simple 2-layer MLP with a *tanh* activation and 64 hidden dimensions. We will train the model using the adjoint method for backpropagation.\n",
        "\n",
        "A quick note on the architectural choices for our model. As mentioned in the first part of this tutorial, the **Picard-Lindel&ouml;f theorem** (Coddington and Levinson, 1955) states that the solution to an initial value problem **exists and is\n",
        "unique** if the differential equation is _uniformly Lipschitz continuous_ in $\\mathbf{z}$ and _continuous_ in $t$. It turns out that this\n",
        "theorem holds for our model if the neural network has finite weights and uses Lipshitz nonlinearities, such as tanh or relu. However, not all tools are our deep learning arsenal is Lipshitz. For example, as shown in [**The Lipschitz Constant of Self-Attention**](https://arxiv.org/abs/2006.04710) by Hyunjik Kim et al., standard self-attention is ___not___ Lipshitz. The authors propose alternative forms of self-attention that are Lipshitz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1RgmVZfKwox"
      },
      "outputs": [],
      "source": [
        "adjoint = True\n",
        "data_module = HalfMoonsDataModule(1000)\n",
        "t_span = torch.linspace(0, 1, 2)\n",
        "f = nn.Sequential(\n",
        "    nn.Linear(2, 64),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(64, 2))\n",
        "model = ODEBlock(f, adjoint=adjoint)\n",
        "learner = Learner(model, t_span)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=200,\n",
        "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "    devices=1,\n",
        "    callbacks=[\n",
        "        pl.callbacks.ModelCheckpoint(mode=\"max\", monitor=\"val_accuracy\"),\n",
        "        pl.callbacks.RichProgressBar(),\n",
        "    ],\n",
        "    log_every_n_steps=1,\n",
        ")\n",
        "trainer.fit(learner, datamodule=data_module)\n",
        "val_result = trainer.validate(learner, datamodule=data_module, verbose=True)\n",
        "test_result = trainer.test(learner, datamodule=data_module, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX5X8l_jgMqm"
      },
      "source": [
        "Excellent! It seems that in less that 200 epochs we have achieved perfect validation accuracy. Let's now use the trained model to run inference and visualize the trajectories using a dense time span of 100 timesteps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "va8pwt0MCAqd"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def run_inference(learner, data_loader, time_span):\n",
        "    learner.to(device)\n",
        "    trajectories = []\n",
        "    classes = []\n",
        "    time_span = torch.from_numpy(time_span).to(device)\n",
        "    for data, target in data_loader:\n",
        "        data = data.to(device)\n",
        "        traj = learner.inference(data, time_span).cpu().numpy()\n",
        "        trajectories.append(traj)\n",
        "        classes.extend(target.numpy())\n",
        "    trajectories = np.concatenate(trajectories, 1)\n",
        "    return trajectories, classes\n",
        "\n",
        "time_span = np.linspace(0.0, 1.0, 100)\n",
        "trajectories, classes = run_inference(learner, data_module.train_dataloader(), time_span)\n",
        "\n",
        "colors = ['coral', 'darkviolet']\n",
        "class_colors = [colors[ci] for ci in classes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U67fOHXLND4j"
      },
      "source": [
        "We will now define a few functions to visualize the learned trajectories, the state-space, and the learned vector field.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3C8gLaTjh3-"
      },
      "outputs": [],
      "source": [
        "#@title You can omit reading this piece of code.\n",
        "\n",
        "def plot_trajectories(time_span, trajectories, class_colors):\n",
        "    fig = plt.figure(figsize=(12,6))\n",
        "    ax0 = fig.add_subplot(121)\n",
        "    ax1 = fig.add_subplot(122)\n",
        "    for i in range(trajectories.shape[1]):\n",
        "        ax0.plot(time_span, trajectories[:, i, 0], color=class_colors[i], alpha=0.1)\n",
        "        ax1.plot(time_span, trajectories[:, i, 1], color=class_colors[i], alpha=0.1)\n",
        "\n",
        "    ax0.set_xlabel(r\"$t$ [Depth]\")\n",
        "    ax0.set_ylabel(r\"$\\mathbf{z}_0(t)$\")\n",
        "    ax0.set_title(\"Dimension 0\")\n",
        "    ax1.set_xlabel(r\"$t$ [Depth]\")\n",
        "    ax1.set_ylabel(r\"$\\mathbf{z}_1(t)$\")\n",
        "    ax1.set_title(\"Dimension 1\")\n",
        "\n",
        "\n",
        "def plot_trajectories_3d(time_span, trajectories, class_colors):\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    for i in range(trajectories.shape[1]):\n",
        "        ax.plot(trajectories[:, i, 0], trajectories[:, i, 1], time_span,\n",
        "                color=class_colors[i], alpha=0.1)\n",
        "\n",
        "    ax.set_title('3D Trajectories')\n",
        "    ax.set_xlabel(r\"$\\mathbf{z}_0(t)$\")\n",
        "    ax.set_ylabel(r\"$\\mathbf{z}_1(t)$\")\n",
        "    ax.set_zlabel(r\"$t$\")\n",
        "\n",
        "\n",
        "def plot_trajectories_animation(time_span, trajectories, colors, classes, lim=10.0):\n",
        "    def animate_frame(t):\n",
        "        ax.cla()\n",
        "        ax.set_xlim(-lim, lim)\n",
        "        ax.set_ylim(-lim, lim)\n",
        "        ax.set_title('Trajectories')\n",
        "        ax.set_xlabel(r\"$\\mathbf{z}_0(t)$\")\n",
        "        ax.set_ylabel(r\"$\\mathbf{z}_1(t)$\")\n",
        "\n",
        "        zero_classes = np.array(classes) == 0\n",
        "        one_classes = np.array(classes) == 1\n",
        "\n",
        "        scatter_zero = ax.plot(\n",
        "            trajectories[t, zero_classes, 0], trajectories[t, zero_classes, 1],\n",
        "            'o', color=colors[0], alpha=0.2+0.8*t/len(time_span))\n",
        "        scatter_one = ax.plot(\n",
        "            trajectories[t, one_classes, 0], trajectories[t, one_classes, 1],\n",
        "            'o', color=colors[1], alpha=0.2+0.8*t/len(time_span))\n",
        "        return scatter_zero, scatter_one\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    ax = fig.add_subplot(111)\n",
        "    anim = FuncAnimation(fig, animate_frame, frames=len(time_span))\n",
        "    plt.close(fig)\n",
        "    return anim\n",
        "\n",
        "\n",
        "def plot_augmented_trajectories_animation(time_span, trajectories, colors, classes, lim=10.0):\n",
        "    def animate_frame(t):\n",
        "        ax.cla()\n",
        "        ax.set_xlim(-lim, lim)\n",
        "        ax.set_ylim(-lim, lim)\n",
        "        ax.set_zlim(-lim, lim)\n",
        "        ax.set_title('Trajectories')\n",
        "        ax.set_xlabel(r\"$\\mathbf{z}_0(t)$\")\n",
        "        ax.set_ylabel(r\"$\\mathbf{z}_1(t)$\")\n",
        "        ax.set_zlabel(r\"$\\mathbf{z}_2(t)$\")\n",
        "\n",
        "        zero_classes = np.array(classes) == 0\n",
        "        one_classes = np.array(classes) == 1\n",
        "\n",
        "        scatter_zero = ax.plot(\n",
        "            trajectories[t, zero_classes, 0], trajectories[t, zero_classes, 1], trajectories[t, zero_classes, 2],\n",
        "            'o', color=colors[0], alpha=0.2+0.8*t/len(time_span))\n",
        "        scatter_one = ax.plot(\n",
        "            trajectories[t, one_classes, 0], trajectories[t, one_classes, 1], trajectories[t, one_classes, 2],\n",
        "            'o', color=colors[1], alpha=0.2+0.8*t/len(time_span))\n",
        "        return scatter_zero, scatter_one\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    anim = FuncAnimation(fig, animate_frame, frames=len(time_span))\n",
        "    plt.close(fig)\n",
        "    return anim\n",
        "\n",
        "\n",
        "def plot_state_space(trajectories, class_colors, ax=None):\n",
        "    if ax is None:\n",
        "        fig = plt.figure(figsize=(8, 8))\n",
        "        ax = fig.add_subplot(111)\n",
        "\n",
        "    for i in range(trajectories.shape[1]):\n",
        "        ax.plot(trajectories[:, i, 0], trajectories[:, i, 1],\n",
        "                color=class_colors[i], alpha=0.1)\n",
        "\n",
        "    ax.set_title('State-Space Diagram')\n",
        "    ax.set_xlabel(r\"$x$\")\n",
        "    ax.set_ylabel(r\"$y$\")\n",
        "\n",
        "\n",
        "def plot_augmented_state_space(trajectories, class_colors, ax=None):\n",
        "    if ax is None:\n",
        "        fig = plt.figure(figsize=(8, 8))\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    for i in range(trajectories.shape[1]):\n",
        "        ax.plot(trajectories[:, i, 0], trajectories[:, i, 1], trajectories[:, i, 2],\n",
        "                color=class_colors[i], alpha=0.1)\n",
        "\n",
        "    ax.set_title('State-Space Diagram')\n",
        "    ax.set_xlabel(r\"$x$\")\n",
        "    ax.set_ylabel(r\"$y$\")\n",
        "    ax.set_zlabel(r\"$z$\")\n",
        "\n",
        "\n",
        "def plot_static_vector_field(model, trajectory, N=50, device='cpu', ax=None):\n",
        "    X, Y = np.mgrid[trajectory[..., 0].min():trajectory[..., 0].max():N*1j,\n",
        "                    trajectory[..., 1].min():trajectory[..., 1].max():N*1j]\n",
        "    X = X.T\n",
        "    Y = Y.T\n",
        "    P = np.vstack([X.ravel(), Y.ravel()]).T\n",
        "    P = torch.Tensor(P).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        vector_field = model.odefunc(0.0, P).cpu()\n",
        "    vector_norm = vector_field.norm(dim=1).view(N, N).numpy()\n",
        "\n",
        "    vector_field = vector_field.view(N, N, 2).numpy()\n",
        "\n",
        "    if ax is None:\n",
        "        fig = plt.figure(figsize=(8, 8))\n",
        "        ax = fig.add_subplot(111)\n",
        "    ax.contourf(X, Y, vector_norm, cmap='RdYlBu')\n",
        "    ax.streamplot(X, Y, vector_field[:, :, 0], vector_field[:, :, 1], color='k')\n",
        "\n",
        "    ax.set_xlim([X.min(), X.max()])\n",
        "    ax.set_ylim([Y.min(), Y.max()])\n",
        "    ax.set_xlabel(r\"$x$\")\n",
        "    ax.set_ylabel(r\"$y$\")\n",
        "    ax.set_title(\"Learned Vector Field\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm8Rx7vQqAG3"
      },
      "source": [
        "Before we visualize the trajectories, let's plot the (training) data once again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kO-qHs0DqJ3h"
      },
      "outputs": [],
      "source": [
        "fig, ax = plot_binary_classification_dataset(*data_module.train_set[:], title='Half Moons Dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q4kqX3XqMSq"
      },
      "source": [
        "Below we visualize the evolution for each of the 2 inputs dimensions as a function of time (depth):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a17ClGrMqUj5"
      },
      "outputs": [],
      "source": [
        "plot_trajectories(time_span, trajectories, class_colors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiVQ_m0JqWw2"
      },
      "source": [
        "And the same evolution combined in a single plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCnJytJfkepv"
      },
      "outputs": [],
      "source": [
        "plot_trajectories_3d(time_span, trajectories, class_colors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Katzs2DZhiD0"
      },
      "source": [
        "The 3D plot can be somewhat complicated to decipher. Thus, we also plot an animated version of the evolution. Each timestep of the animation is a slice on the temporal axis of the figure above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu16sfBBqaau"
      },
      "outputs": [],
      "source": [
        "anim = plot_trajectories_animation(time_span, trajectories, colors, classes, lim=8.0)\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiGXhIt4rWD2"
      },
      "source": [
        "Finally, let's visualize the state-space diagram and the learned vector field:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHPy-cx66sIM"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
        "plot_state_space(trajectories, class_colors, ax=ax[0])\n",
        "plot_static_vector_field(model, trajectories, ax=ax[1], device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yOsVxoajpDV"
      },
      "source": [
        "### Neural ODEs can only describe homeomorphisms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b14Tn30iGgL"
      },
      "source": [
        "It seems that the network can indeed do a very good job at separating data from these 2 classes. We will now move to different setting, which appears similar at first in terms of difficulty, but will turn out to be very hard, even impossible theoretically for Neural ODEs to solve in their basic form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_XZKKzlro54"
      },
      "source": [
        "Neural ODEs describe homeomorphisms (flows). Inputs/hidden states/outputs have\n",
        "the same dimensionality. They form non-intersecting trajectories.\n",
        "\n",
        "Since Neural ODEs cannot model non-homeomorphisms, they cannot, for example, separate a 2d concentric annuli/circles dataset.\n",
        "\n",
        "$$ 0 < r_1 < r_2 < r_3, \\quad g: \\mathbb{R}^2 \\to \\mathbb{R} $$\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "  g(\\mathbf{x}) = 0, & \\lVert \\mathbf{x}\\rVert \\leq r_1,\\\\\n",
        "  g(\\mathbf{x}) = 1, & r_2 \\leq \\lVert \\mathbf{x}\\rVert \\leq r_3\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/DL2/Dynamical_systems/2d_circles_dataset.png?raw=1\" width=\"200px\"></center>\n",
        "\n",
        "(Figure credit: [Emilien Dupont et al.](https://arxiv.org/abs/1904.01681))\n",
        "\n",
        "Neural ODEs cannot represent that function, the features of NODEs preserve the topology of the input space.\n",
        "NODEs can only continuously deform the input space, and cannot, for\n",
        "example, tear a connected region apart.\n",
        "\n",
        "In practice, however, Neural ODEs are not trained on continuous regions of space, they are rather trained on a finite number of\n",
        "data points. This means that NODEs can \"cheat\" and stretch space, squeezing through the gaps between data points.\n",
        "This can lead to ill-posed ODE problems that are numerically expensive to solve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wy6JNO9ueR-"
      },
      "source": [
        "Let's see this effect in practice. First, we will define a similar dataset that comprises 2 2D concentric circles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYJRbSXCzK-_"
      },
      "outputs": [],
      "source": [
        "def rand_sphere(num_samples:int, dim:int, radius:float) -> torch.Tensor:\n",
        "    \"\"\"Uniform sample from a `dim`-dimensional sphere of radius `radius`\n",
        "    :param num_samples: number of points to sample\n",
        "    :type num_samples: int\n",
        "    :param dim: dimension of the hyper-sphere\n",
        "    :type dim: int\n",
        "    :param radius: radius of the hyper-sphere\n",
        "    :type radius: float\n",
        "    \"\"\"\n",
        "    v = torch.randn(num_samples, dim)\n",
        "    points = radius * F.normalize(v, dim=-1)\n",
        "    return points\n",
        "\n",
        "\n",
        "class ConcentricCircles(Dataset):\n",
        "    \"\"\"Concentric Circles Classification Dataset\n",
        "\n",
        "    Adapted from https://github.com/DiffEqML/torchdyn\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples=100, noise_std=1e-4, inner_radius=0.5,\n",
        "                 outer_radius=1.0):\n",
        "        self.num_samples = num_samples\n",
        "        self.noise_std = noise_std\n",
        "        self.X, self.y = self.generate_concentric_circles(num_samples, noise_std)\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_concentric_circles(num_samples:int=100, noise_std:float=1e-4,\n",
        "                                    inner_radius:float=0.5, outer_radius:int=1.0):\n",
        "        \"\"\"Creates a *concentric circles* dataset of `num_samples` datasets points.\n",
        "        :param num_samples: number of datasets points in the generated dataset\n",
        "        :type num_samples: int\n",
        "        :param noise_std: standard deviation of noise magnitude added to each datasets point\n",
        "        :type noise_std: float\n",
        "        :param inner_radius: radius of the inner circle\n",
        "        :type inner_radius: float\n",
        "        :param outer_radius: radius of the outer circle\n",
        "        :type outer_radius: float\n",
        "        \"\"\"\n",
        "        y = torch.zeros(num_samples, dtype=torch.long)\n",
        "        y[:num_samples // 2] = 1\n",
        "\n",
        "        X = torch.zeros((num_samples, 2))\n",
        "        X[:num_samples // 2] = rand_sphere(num_samples // 2, 2, inner_radius)\n",
        "        X[num_samples // 2:] = rand_sphere(num_samples - num_samples // 2, 2, outer_radius)\n",
        "        X += noise_std * torch.randn((num_samples, 2))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "class ConcentricCirclesDataModule(ToyDataModule):\n",
        "    def __init__(self, dataset_size:int, split_percentages:Optional[float]=None):\n",
        "        super().__init__(dataset_size, split_percentages=split_percentages)\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None):\n",
        "        dataset = ConcentricCircles(num_samples=self.dataset_size, noise_std=5e-2)\n",
        "        self.train_set, self.val_set, self.test_set = torch.utils.data.random_split(dataset, self.split_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WUE6cMzz02c"
      },
      "outputs": [],
      "source": [
        "sample_circles_set = ConcentricCircles(num_samples=401, noise_std=5e-2)\n",
        "fig, ax = plot_binary_classification_dataset(*sample_circles_set[:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXhHrkd7usBq"
      },
      "source": [
        "We will now train a Neural ODE on this dataset. We will use a 3-layer MLP with ReLU activations and 64 hidden dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c1kG52ILG7w"
      },
      "outputs": [],
      "source": [
        "circles_data_module = ConcentricCirclesDataModule(1000)\n",
        "\n",
        "adjoint = True\n",
        "t_span = torch.linspace(0, 1, 2)\n",
        "f = nn.Sequential(nn.Linear(2, 64), nn.Tanh(), nn.Linear(64, 64), nn.Tanh(), nn.Linear(64, 2))\n",
        "model = ODEBlock(f, adjoint=adjoint)\n",
        "learner = Learner(model, t_span)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=300,\n",
        "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "    devices=1,\n",
        "    callbacks=[\n",
        "        pl.callbacks.ModelCheckpoint(mode=\"max\", monitor=\"val_accuracy\"),\n",
        "        pl.callbacks.RichProgressBar(),\n",
        "    ],\n",
        "    log_every_n_steps=1,\n",
        ")\n",
        "\n",
        "trainer.fit(learner, datamodule=circles_data_module)\n",
        "val_result = trainer.validate(learner, datamodule=circles_data_module, verbose=True)\n",
        "test_result = trainer.test(learner, datamodule=circles_data_module, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAkjyBtWu-Qq"
      },
      "source": [
        "Interestingly, the model can achieve perfect accuracy, even though in theory it cannot separate the 2 classes. Let's visualize the trajectories and see how this can be the case. SImilar to the previous experiment, we will first run inference and save the trajectories using a dense time span."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Txb_7s_2MqdP"
      },
      "outputs": [],
      "source": [
        "num_timesteps = 100\n",
        "time_span = np.linspace(0.0, 1.0, num_timesteps)\n",
        "trajectories, classes = run_inference(learner, circles_data_module.train_dataloader(), time_span)\n",
        "\n",
        "colors = ['coral', 'darkviolet']\n",
        "class_colors = [colors[ci] for ci in classes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vn_qvffMb_c"
      },
      "outputs": [],
      "source": [
        "plot_trajectories(time_span, trajectories, class_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udB9F1pQMiCu"
      },
      "outputs": [],
      "source": [
        "plot_trajectories_3d(time_span, trajectories, class_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dgd7wIOqMhca"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
        "plot_state_space(trajectories, class_colors, ax=ax[0])\n",
        "plot_static_vector_field(model, trajectories, ax=ax[1], device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biPyHJeTvpmq"
      },
      "source": [
        "It is not clear neither from the trajectories, nor from the state-space, how the model manages to separate the data. Let's use an animated visualization of the evolution once again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRi43TsjwmmZ"
      },
      "outputs": [],
      "source": [
        "anim = plot_trajectories_animation(time_span, trajectories, colors, classes, lim=12.0)\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT7IrcPNwbBL"
      },
      "source": [
        "The animation clearly shows that the model is cheating by stretching a part of space so much that data points from the inner circle can flow that region. Even though this offers perfect accuracy in this dataset, it comes at the expense of generalization capabilities, and increased train and inference time, since the network has to run many more function evaluations to achieve these results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJZGdyoOxGOG"
      },
      "source": [
        "### Augmented Neural ODEs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Ku5vKsQNIy"
      },
      "source": [
        "These issues were first observed (in the context of Neural ODEs) by Emilien Dupont et al., in their work on [**Augmented Neural ODEs**](https://arxiv.org/abs/1904.01681). The authors propose a very simple yet elegant solution to the problem: they augment the space on which they learn and solve the ODE, from\n",
        "$\\mathbb{R}^d$ to $\\mathbb{R}^{d+p}$.\n",
        "The initial state $\\mathbf{x}$ is augmented with additional dimensions $\\mathbf{a}$ that are initialized with 0.\n",
        "\n",
        "The augmented ODE problem is formulated as:\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{\\dot{h}}(t)\n",
        "\\\\\n",
        "\\mathbf{\\dot{a}}(t)\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\mathbf{f}\n",
        "\\left(\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{\\dot{h}}(t)\n",
        "\\\\\n",
        "\\mathbf{\\dot{a}}(t)\n",
        "\\end{bmatrix}    \n",
        "\\right),\n",
        "\\ \\ \\\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{h}(0)\n",
        "\\\\\n",
        "\\mathbf{a}(0)\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{x}\n",
        "\\\\\n",
        "\\mathbf{0}\n",
        "\\end{bmatrix}   \n",
        "$$\n",
        "\n",
        "The final predictions in the original space are achieved via a final network that transforms the output augmented states:\n",
        "\n",
        "$$\n",
        "\\mathbf{\\hat{y}} =\n",
        "\\mathbf{g}\n",
        "\\left(\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{h}(T)\n",
        "\\\\\n",
        "\\mathbf{a}(T)\n",
        "\\end{bmatrix}\n",
        "\\right),\n",
        "$$\n",
        "\n",
        "where $\\mathbf{g}$ can be an *MLP* or even a simple *linear* layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acesQ-dJU1_p"
      },
      "source": [
        "We will now define a simple Augmenter module, and a Neural ODE wrapper that incorporates the Augmenter and the output network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPMtEfZ_r_qK"
      },
      "outputs": [],
      "source": [
        "class ZeroAugmenter(nn.Module):\n",
        "    def __init__(self, axis=1, num_dims=1):\n",
        "        super().__init__()\n",
        "        self.axis = axis\n",
        "        self.num_dims = num_dims\n",
        "\n",
        "    def forward(self, x):\n",
        "        aug_dims = list(x.shape)\n",
        "        aug_dims[self.axis] = self.num_dims\n",
        "        augmentation = torch.zeros(aug_dims, device=x.device, dtype=x.dtype)\n",
        "        return torch.cat([x, augmentation], dim=self.axis)\n",
        "\n",
        "\n",
        "class AugmentedNODEWrapper(nn.Module):\n",
        "    def __init__(self, augmenter, neural_ode, out_net):\n",
        "        super().__init__()\n",
        "        self.augmenter = augmenter\n",
        "        self.neural_ode = neural_ode\n",
        "        self.out_net = out_net\n",
        "\n",
        "    def forward(self, x: torch.Tensor, adjoint: bool = True, integration_time=None):\n",
        "        x = self.augmenter(x)\n",
        "        x = self.neural_ode(x, adjoint, integration_time)\n",
        "        x = self.out_net(x)\n",
        "        return x\n",
        "\n",
        "    def forward_no_projection(self, x: torch.Tensor, adjoint: bool = True, integration_time=None):\n",
        "        x = self.augmenter(x)\n",
        "        x = self.neural_ode(x, adjoint, integration_time)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48Lgbe_MVGF1"
      },
      "source": [
        "We will continue with the same dataset as before, namely the 2D concentric circles. We will use a single augmentation dimension and a simple linear layer $\\mathbf{g}: \\mathbb{R}^3 \\to \\mathbb{R}^2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itIgM3ckr1KF"
      },
      "outputs": [],
      "source": [
        "circles_data_module = ConcentricCirclesDataModule(1000)\n",
        "\n",
        "adjoint = True\n",
        "t_span = torch.linspace(0, 1, 2)\n",
        "augmentation_dims = 1\n",
        "f = nn.Sequential(nn.Linear(2+augmentation_dims, 64), nn.Tanh(), nn.Linear(64, 2+augmentation_dims))\n",
        "no_augm_model = ODEBlock(f, adjoint=adjoint)\n",
        "model = AugmentedNODEWrapper(ZeroAugmenter(num_dims=augmentation_dims), no_augm_model, nn.Linear(2+augmentation_dims, 2))\n",
        "learner = Learner(model, t_span)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=100,\n",
        "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "    devices=1,\n",
        "    callbacks=[\n",
        "        pl.callbacks.ModelCheckpoint(mode=\"max\", monitor=\"val_accuracy\"),\n",
        "        pl.callbacks.RichProgressBar(),\n",
        "    ],\n",
        "    log_every_n_steps=1,\n",
        ")\n",
        "\n",
        "trainer.fit(learner, datamodule=circles_data_module)\n",
        "val_result = trainer.validate(learner, datamodule=circles_data_module, verbose=True)\n",
        "test_result = trainer.test(learner, datamodule=circles_data_module, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D93axj_1Vi2U"
      },
      "source": [
        "Even with a single augmentation dimension, the model can very quickly achieve perfect accuracy in the validation set. Let us now compute and visualize the trajectories, in order to gain a better understanding of what is actually going on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWDmQVp505FD"
      },
      "outputs": [],
      "source": [
        "num_timesteps = 100\n",
        "time_span = np.linspace(0.0, 1.0, num_timesteps)\n",
        "trajectories, classes = run_inference(learner, circles_data_module.train_dataloader(), time_span)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9W2ey920029"
      },
      "outputs": [],
      "source": [
        "plot_state_space(trajectories, class_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It3kwa5SFwDr"
      },
      "outputs": [],
      "source": [
        "anim = plot_trajectories_animation(time_span, trajectories, colors, classes, lim=8.0)\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIxbW9OgV_Zl"
      },
      "source": [
        "From the 2D plots, it is not exactly clear how the model can achieve perfect separation. Thus, in what follows, we will visualize the trajectories and the state-space in the augmented 3D space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPwYpC-kQMvy"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def run_inference_no_projection(learner, data_loader, time_span):\n",
        "    trajectories = []\n",
        "    classes = []\n",
        "    learner = learner.to(device)\n",
        "    time_span = torch.from_numpy(time_span).to(device)\n",
        "    for data, target in data_loader:\n",
        "        data = data.to(device)\n",
        "        traj = learner.inference_no_projection(data, time_span).cpu().numpy()\n",
        "        trajectories.append(traj)\n",
        "        classes.extend(target.numpy())\n",
        "    trajectories = np.concatenate(trajectories, 1)\n",
        "    return trajectories, classes\n",
        "\n",
        "num_timesteps = 100\n",
        "time_span = np.linspace(0.0, 1.0, num_timesteps)\n",
        "trajectories, classes = run_inference_no_projection(learner, circles_data_module.train_dataloader(), time_span)\n",
        "colors = ['coral', 'darkviolet']\n",
        "class_colors = [colors[ci] for ci in classes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTiq4UbxQ0A5"
      },
      "outputs": [],
      "source": [
        "plot_augmented_state_space(trajectories, class_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZJcr-PiRepl"
      },
      "outputs": [],
      "source": [
        "anim = plot_augmented_trajectories_animation(time_span, trajectories, colors, classes, lim=8.0)\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-RYAWuY8CZy"
      },
      "source": [
        "## Further Reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm1p53MFIBpf"
      },
      "source": [
        "Neural ODEs is an exciting topic that has received a lot of attention in the past few years, ever since their introduction in Neurips 2018. Some of many many work in this field include:\n",
        "\n",
        "- Neural Stochastic Differential Equations (Neural SDEs)\n",
        "- Neural Controlled Differential Equations (Neural CDEs)\n",
        "- Graph ODEs\n",
        "- Hamiltonial Neural Networks\n",
        "- Lagrangian Neural Networks\n",
        "\n",
        "If you want to see a quick overview of different works in the field, [Michael Poli](https://zymrael.github.io/) maintains the excellent [Awesome Neural ODE](https://github.com/Zymrael/awesome-neural-ode),\n",
        "a collection of resources regarding the interplay between neural differential equations, dynamical systems, deep learning, control, numerical methods and scientific machine learning.\n",
        "\n",
        "[Torchdyn](https://github.com/DiffEqML/torchdyn) is an excellent library for Neural Differential Equations.\n",
        "\n",
        "[Implicit Layers](https://implicit-layers-tutorial.org/) is a list of tutorials\n",
        "on implicit functions and automatic differentiation, Neural ODEs, and Deep Equilibrium Models.\n",
        "\n",
        "[Here](https://jontysinai.github.io/jekyll/update/2019/01/18/understanding-neural-odes.html) is an excellent blogpost on ODEs and Neural ODEs.\n",
        "\n",
        "[Patrick Kidger](https://kidger.site/)'s doctoral dissertation is an excellent textbook on [Neural Differential Equations](https://arxiv.org/abs/2202.02435)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfWI3IMj6sIP"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H63Q3z9S6sIP"
      },
      "source": [
        "[1] Chen, Ricky T. Q. et al. \"**Neural ordinary differential equations**\". _NeurIPS_ 2018. https://arxiv.org/abs/1806.07366\n",
        "\n",
        "[2] Dupont, Emilien et al. \"**Augmented Neural ODEs**\". _NeurIPS_ 2019. https://arxiv.org/abs/1904.01681\n",
        "\n",
        "[3] Pontryagin, L.S. et al. \"**The mathematical theory of optimal processes**\". 1962"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "dynamical-systems-neural-odes.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}